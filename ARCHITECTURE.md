# Odin 导航栈架构说明 (Odin Navigation Architecture)

## 1. 系统架构总览

本项目是一个集成了视觉感知、语义理解与多级规划的四足机器人导航系统。

### 系统逻辑架构 (逻辑框架)

![Odin 导航栈逻辑架构](file:///c:/Users/gwpsc/.gemini/antigravity/brain/9c7181c6-eadb-4109-b0a0-c6d02cfa37e6/odin_logical_arch_cn_1767142123104.png)

### 数据流架构 (数据流向)

![Odin 导航栈数据流架构](file:///c:/Users/gwpsc/.gemini/antigravity/brain/9c7181c6-eadb-4109-b0a0-c6d02cfa37e6/odin_data_flow_cn_1767142150666.png)

---

## 2. 核心层级说明

### 2.1 感知层 (Perception Layer)
*   **YOLO 物体检测**: 实时识别环境中的椅子、人、桌子等语义目标。
*   **3D 视觉定位**: 结合深度图信息，将检测到的 2D 目标映射到 3D 空间坐标。
*   **语义指令解析**: 支持自然语言指令（如“走到那个红色的椅子旁边”），通过语义查询节点转化为具体的导航目标。

### 2.2 规划层 (Planning Layer)
*   **A* 全局规划**: 在栅格地图上寻找从当前位置到目标的全局最优路径。
*   **DWA (Dynamic Window Approach)**: 默认局部避障算法，通过速度采样和轨迹模拟，实现动态避障。
*   **NeuPAN (神经网络规划)**: 实验性端到端局部规划方案，具有极高的规划频率（50Hz+）和更平滑的避障表现。
*   **局部代价地图 (Local Costmap)**: 维护一个随机器人滚动的实时障碍物地图，支持“记忆衰减”机制，能有效处理动态障碍。

### 2.3 控制层 (Control Layer)
*   **Unitree 运动控制器**: 将速度指令 (`/cmd_vel`) 转发给四足机器人底盘，驱动电机执行具体步态。

---

## 3. 核心数据流 (Data Flow)

1.  **输入**: 激光扫描 (`/scan`)、点云 (`/odin1/cloud`)、RGB-D 图像。
2.  **处理**: 
    - 激光数据进入 **局部代价地图**。
    - 图像数据进入 **YOLO 探测器** 提取目标位姿。
3.  **决策**: **目标状态机** 决定当前阶段任务，调用 **A*** 生成全局路径。
4.  **执行**: **DWA** 依据全局路径和代价值生成最优速度，传递给 **Unitree 控制器**。

---

## 4. 关键改进点 (对比标准 DWA)

- **障碍物记忆衰减**: 自动清理残留噪点和动态物体阴影。
- **航向提升评分**: 强化机器人在原地转向时的响应速度。
- **轻量化工程实现**: 舍弃了臃肿的官方 Costmap 库，直接操作内存栅格，适合嵌入式部署。
